
# Lexical Analysis
	Reads stream of characters and groups them into meaningful units called lexems or lexical units. Corresponding to each lexeme it returns a token to the parser.
		A Token is an entity composed of a name and an optional attribute.
		It also strips out whitespaces, comments and correlates  errors with the corresponding line numbers in the source program. 
		Lexical units can be classified into identifiers, keywords, punctuations, operators, numeric constants, literals etc.
		LEX analyser  returs a token corresponding to each category. For example id for identifier. The token contains additional attribute pertaining to the it. Commonly it contains a pointer to the symbol table entry for the identifier.
		Numeric constant :- *id* with attribute as the constant value
		Literal :- *literal* with string constant as the attribute value
		Operator :- *op* with operator as attribute or a single token for the symbol like *plus* or *minus*

```C
	== 3.14 ∗ 16 ∗ 16
    == < num, 3.14 > < op, ∗ > < num, 16 > < op, ∗ > < num, 16 >
```
## Pattern specification
	For each token there should be a regular expression that matches it. The lexer should know the pattern describing each token.
	A string that matches the pattern for a token is know as a lexeme.

```ruby
digit → 0|1|2|3|4|5|6|7|8|9
letter → A|B| . . . |Z|a|b| . . . |z
id → letter(letter|digit)
```

	 Here the arrow assigns a name to each regular expression. Then these names can be used instead of the regualr expression.


## Recognition of tokens
	Reads input stream and returns token corresponding to longest matching prefix. The recognition process can be modeled with a state transition diagram.

![[Pasted image 20250122203850.png]]

	Sometimes the scanner needs to scan an additional symbol that is not part of the lexeme. In that case the pointer needs to be brought back by one position this is denoted by a -- * -- symbol.

### Automatic lexical analyzer generator
	Tools like lex/flex can be used to generate lexical analysers.
	The specifications of the required analyzer is written as a Lex Program in a Lex file. The file is written as a combination of regualr expressions, describing the pattern for the tokens. The lex compiler compiles the program into a C program, which contains an equivalent finite automaton and providing a driver for the automaton. Given n patterns P1 P2 P3 the tool builds a combined regular expression P1|P2|P3. In the lex program a code fragment can be associated with each pattern. The code is run when the longest prefix of the input matches the correspoding pattern.


# Parsing
## Types
	1) Universal 
		parse any grammar (CYK algorithm) n^3 algo
		1) Compilers commonly use
			1) Top Down parsing
			2) Bottom Up parsing
## Lexical Analysis
	Input : Program as a stream of characters, And the specification of tokens.
	Output : Stream of tokens (one token corresponding to each lexeme)
## Syntax Analysis aka parsing
	Input : Token stream, Syntax specification of the programming language in the form of context free grammar(CFG)
	Checks if sequence of token names can be generated by the given grammar by simulating the parse tree.
	Create/Update symbol table entries, type checking, intermediate code generation.
	Output : Parse tree, or some intermediate representation of the program, if parsing is successful.

### BNF ( Backus-Naur Form)
	
### CFG (Context Free Grammar)
	G = (V, T, P, S)
		Variables/Non Terminals, Terminals, Productions rules, Start symbol
#### Derivation
	i/p : id = id + id
	
![[Pasted image 20250124150316.png]]

	derivation : replace a non terminal with a string of grammar symbols.

![[Pasted image 20250124150425.png]]

#### Sentential form
$$
	 If \space S \star\rightarrow \alpha \space we \space say \space \alpha \space is \space in \space sentential \space form  
$$
	
	A Sentence is a sentential form with non non-terminals.

$$
L(G) \space is \space the \space set \space of \space sentences \space derivalbe \space from \space the \space start \space symbol \space G
$$
$$
A \space string \space of \space symbols \space \epsilon \space L(G) \space only \space if \space S \space \star \rightarrow w 
$$
	Leftmost derivation : keep deriving the leftmost non-terminal
	Rightmost derivation : keep deriving the rightmost non-terminal
### Parsing
#### Parse trees
![[Pasted image 20250124151435.png]]

	An ambigous grammar has more than one leftmost derivation or rightmost derivation or parse tree.
#### Top down parsing
	Start from root node as the start symbol. Keep adding nodes in preorder.
	PREORDER
		visit current node
		visit left node in preorder
		visit right node in preorder
	HOW ?
		if non terminal
			choose appropriate production and add nodes
		if terminal
			skip to next node
	This is equivalent to finding a leftmost derivation

#### Bottom-Up Parsing
	Start with leaf nodes represnting the input stream of characters.
	At each step replace the leftmost symbol with a matching production symbol.

#### Recursive decent parsing
```C
S(){
	match(‘c’);
	A();
	match(‘d’);
}
A(){
	match(‘a’);
	match(‘b’);
}
// match(x) : compares the next input symbol, if same : advances the pointer by one, else : reports error.
```

		Recursive-Descent with backtracking, if multiple choices, choose one, if error occurs go back and choose next, if eroor persists for all choices return error.

#### Predictive parsing
	keep a lookahead pointer that points to the next symbol, then try to match the lookahead symbol with a production rule. parser predicts the production based on the look-ahead symbol.
##### FIRST(A)
	Defined as the set of first non-terminals that can be derived from the symbol A. empty symbol can also be in FIRST(A) 
	eg: A -> B | C
		B -> amk
		B -> ksg
		C -> qwe

$$FIRST (A) = FIRST(B)  \cup  FIRST(C) =  {a, k, q}$$
$$FIRST(B) = {a, k}$$
$$FIRST(C) = {q}$$
	If lookahead an element in FIRST(B) choose B else if element in FIRST(C) choose C else error.
	If FIRST(B) and FIRST(C) are disjoint a parsing decision can be made by the lookahead symbol. 

#### Predictive parsing table based on FIRST sets

|     | id            | num                | -                | $         |
| --- | ------------- | ------------------ | ---------------- | --------- |
| $S$ | $S → id = E$  | **error**          | **error**        | **error** |
| $E$ | $E → id + id$ | $E\rightarrow num$ | $E\rightarrow -$ | **error** |

	Algorithm : 
		for each production A -> a:
			for each symbol k in FIRST(a):
				add A -> a in entry T[A, k]

#### CFG with null production
	A -> Cd
	C -> ab | ε
	Where will we choose C -> ε production ? 

![[Pasted image 20250124162037.png]]

	if d ε FOLLOW(C)
#### FOLLOW(A)
	The set of terminals that can appear to the right of A in a sentential form. In addition if it is the rightmost symbol in some sentential form then $ is also in the set of FOLLOW(A). -- SENTENTIAL FORM --
	
																											S ∗⇒ αAaβ
	1) S $
	2) E + E $
	3) id + E $
	Here S is followed by $, E is followed by + and $, id is followed by + and likewise.
#### Parsing table using follow
![[Pasted image 20250124175243.png]]

![[Pasted image 20250124175248.png]]

	for each production A -> a:
		if € an element of FIRST(a):
			for each terminal b € FOLLOW(A):
				add (A -> a) in T[A, b]
	Productions like this are not suitable for predictive parsing:
	
																						E → id + id | id ∗ id 


#### Grammar Transformation
	Convert the given non predictive grammar to an equivalent predictable form.
	E → id + id | id ∗ id
	an equivalent grammar suitable for predictive parsing
	E → idB
	B → +id | ∗ id

##### Left Factoring
	E → id + id | id ∗ id
	id is common on the left side, that is maintained and rest is replaced by B
	E → idB
	B →  + id | ∗ id
##### Right Factoring

	

## Semantic Analysis
	