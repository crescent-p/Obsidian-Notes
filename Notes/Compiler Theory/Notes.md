# Lexical Analysis
	Reads stream of characters and groups them into meaningful units called lexems or lexical units. Corresponding to each lexeme it returns a token to the parser.
		A Token is an entity composed of a name and an optional attribute.
		It also strips out whitespaces, comments and correlates  errors with the corresponding line numbers in the source program. 
		Lexical units can be classified into identifiers, keywords, punctuations, operators, numeric constants, literals etc.
		LEX analyser  returs a token corresponding to each category. For example id for identifier. The token contains additional attribute pertaining to the it. Commonly it contains a pointer to the symbol table entry for the identifier.
		Numeric constant :- *id* with attribute as the constant value
		Literal :- *literal* with string constant as the attribute value
		Operator :- *op* with operator as attribute or a single token for the symbol like *plus* or *minus*

```C
	== 3.14 ∗ 16 ∗ 16
    == < num, 3.14 > < op, ∗ > < num, 16 > < op, ∗ > < num, 16 >
```
## Pattern specification
	For each token there should be a regular expression that matches it. The lexer should know the pattern describing each token.
	A string that matches the pattern for a token is know as a lexeme.

```ruby
digit → 0|1|2|3|4|5|6|7|8|9
letter → A|B| . . . |Z|a|b| . . . |z
id → letter(letter|digit)
```

	 Here the arrow assigns a name to each regular expression. Then these names can be used instead of the regualr expression.


## Recognition of tokens
	Reads input stream and returns token corresponding to longest matching prefix. The recognition process can be modeled with a state transition diagram.

![[Pasted image 20250122203850.png]]

	Sometimes the scanner needs to scan an additional symbol that is not part of the lexeme. In that case the pointer needs to be brought back by one position this is denoted by a -- * -- symbol.

### Automatic lexical analyzer generator
	Tools like lex/flex can be used to generate lexical analysers.
	The specifications of the required analyzer is written as a Lex Program in a Lex file. The file is written as a combination of regualr expressions, describing the pattern for the tokens. The lex compiler compiles the program into a C program, which contains an equivalent finite automaton and providing a driver for the automaton. Given n patterns P1 P2 P3 the tool builds a combined regular expression P1|P2|P3. In the lex program a code fragment can be associated with each pattern. The code is run when the longest prefix of the input matches the correspoding pattern.


# Parsing
## Types
	1) Universal 
		parse any grammar (CYK algorithm) n^3 algo
		1) Compilers commonly use
			1) Top Down parsing
			2) Bottom Up parsing
## Lexical Analysis
	Input : Program as a stream of characters, And the specification of tokens.
	Output : Stream of tokens (one token corresponding to each lexeme)
## Syntax Analysis aka parsing
	Input : Token stream, Syntax specification of the programming language in the form of context free grammar(CFG)
	Checks if sequence of token names can be generated by the given grammar by simulating the parse tree.
	Create/Update symbol table entries, type checking, intermediate code generation.
	Output : Parse tree, or some intermediate representation of the program, if parsing is successful.

### BNF ( Backus-Naur Form)
	
### CFG (Context Free Grammar)
	G = (V, T, P, S)
		Variables/Non Terminals, Terminals, Productions rules, Start symbol
#### Derivation
	i/p : id = id + id
	
![[Pasted image 20250124150316.png]]

	derivation : replace a non terminal with a string of grammar symbols.

![[Pasted image 20250124150425.png]]

#### Sentential form
$$
	 If \space S \star\rightarrow \alpha \space we \space say \space \alpha \space is \space in \space sentential \space form  
$$
	
	A Sentence is a sentential form with non non-terminals.

$$
L(G) \space is \space the \space set \space of \space sentences \space derivalbe \space from \space the \space start \space symbol \space G
$$
$$
A \space string \space of \space symbols \space \epsilon \space L(G) \space only \space if \space S \space \star \rightarrow w 
$$
	Leftmost derivation : keep deriving the leftmost non-terminal
	Rightmost derivation : keep deriving the rightmost non-terminal
### Parsing
#### Parse trees
![[Pasted image 20250124151435.png]]

	An ambigous grammar has more than one leftmost derivation or rightmost derivation or parse tree.
#### Top down parsing
	Start from root node as the start symbol. Keep adding nodes in preorder.
	PREORDER
		visit current node
		visit left node in preorder
		visit right node in preorder
	HOW ?
		if non terminal
			choose appropriate production and add nodes
		if terminal
			skip to next node
	This is equivalent to finding a leftmost derivation

#### Bottom-Up Parsing
	Start with leaf nodes represnting the input stream of characters.
	At each step replace the leftmost symbol with a matching production symbol.

#### Recursive decent parsing
```C
S(){
	match(‘c’);
	A();
	match(‘d’);
}
A(){
	match(‘a’);
	match(‘b’);
}
// match(x) : compares the next input symbol, if same : advances the pointer by one, else : reports error.
```

		Recursive-Descent with backtracking, if multiple choices, choose one, if error occurs go back and choose next, if eroor persists for all choices return error.

#### Predictive parsing
	keep a lookahead pointer that points to the next symbol, then try to match the lookahead symbol with a production rule. parser predicts the production based on the look-ahead symbol.
##### FIRST(A)
	Defined as the set of first non-terminals that can be derived from the symbol A. empty symbol can also be in FIRST(A) 
	eg: A -> B | C
		B -> amk
		B -> ksg
		C -> qwe

$$FIRST (A) = FIRST(B)  \cup  FIRST(C) =  {a, k, q}$$
$$FIRST(B) = {a, k}$$
$$FIRST(C) = {q}$$
	If lookahead an element in FIRST(B) choose B else if element in FIRST(C) choose C else error.
	If FIRST(B) and FIRST(C) are disjoint a parsing decision can be made by the lookahead symbol. 
	If A -> a then add everything in FIRST(a) to FIRST(A)

#### Predictive parsing table based on FIRST sets

|     | id            | num                | -                | $         |
| --- | ------------- | ------------------ | ---------------- | --------- |
| $S$ | $S → id = E$  | **error**          | **error**        | **error** |
| $E$ | $E → id + id$ | $E\rightarrow num$ | $E\rightarrow -$ | **error** |

	Algorithm : 
		for each production A -> a:
			for each symbol k in FIRST(a):
				add A -> a in entry T[A, k]

#### CFG with null production
	A -> Cd
	C -> ab | ε
	Where will we choose C -> ε production ? 

![[Pasted image 20250124162037.png]]

	if d ε FOLLOW(C)
#### FOLLOW(A)
	The set of terminals that can appear to the right of A in a sentential form. In addition if it is the rightmost symbol in some sentential form then $ is also in the set of FOLLOW(A). -- SENTENTIAL FORM --
	Try writing the sentential forms and write follow from that, even an intermediate step is enough to be included as a FOLLOW element.
	If A -> aB add everything in FOLLOW(A) to FOLLOW(B)
	
																											S ∗⇒ αAaβ
	1) S $
	2) E + E $
	3) id + E $
	Here S is followed by $, E is followed by + and $, id is followed by + and likewise.
	Steps to compute FOLLOW(S): S is the start symbol
		1) place $ in FOLLOW(S)
		2) if there is a production A -> aBb then add everthing except ε of FIRST(b) in FOLLOW(B)
		3) if there is a produtction A -> aBb and if b contains ε then add everything in FOLLOW(A) to FOLLOW(B)
		4) if there is a production A -> aB then add everything in FOLLOW(A) to FOLLOW(B)
#### Parsing table using follow
![[Pasted image 20250124175243.png]]

![[Pasted image 20250124175248.png]]

	for each production A -> a:
		if € an element of FIRST(a):
			for each terminal b € FOLLOW(A):
				add (A -> a) in T[A, b]
	Productions like this are not suitable for predictive parsing:
	
																						E → id + id | id ∗ id 
	Steps in making creating predictive parsing table:
		1) for each terminal a ε FIRST(A) add A -> a in T[A, a]
		2) if ε in FIRST(A), for each terminal b in FOLLOW(A) add A -> a in T[A, b]
			because sometimes you might need to choose a production that gives epsilon on first to get the correct symbol which might come in the second position.
		3) if ϵ is in FIRST(α), and $ is in FOLLOW (A), add A → α to T[A, $].

#### Grammar Transformation
	Convert the given non predictive grammar to an equivalent predictable form.
	E → id + id | id ∗ id
	an equivalent grammar suitable for predictive parsing
	E → idB
	B → +id | ∗ id

##### Left Factoring
	E → id + id | id ∗ id
	id is common on the left side, that is maintained and rest is replaced by B
	E → idB
	B →  + id | ∗ id
##### Right Factoring

	

### Non Recursive Predictive Parsing

	Input : string S and Parsing table T for grammar G
	Output : If S belong to grammar G or not. IF yes give leftmost derivation of w.

### LL(1) Grammar
	A grammar for which predictive parsing table can be built with one symbol look ahead is called LL(1) grammar. 
	- Left to right
	- Leftmost derivation 
	- 1 for one symbol look ahead.
	- E → id + id | id ∗ id is not LL(1) because it needs to look ahead two symbols to decide the next production.
	- if A -> a | b and FIRST(a) intersection FIRST(b) is not null then it is not suitable for predictive parsing.
#### Rules
	1) FIRST(a), FIRST(b) should be disjoint
	2) If ε is in FIRST(A), then FIRST(B) should not contain any terminal in FOLLOW(A)
	3) If ϵ is in FIRST(β), then FIRST(α) should not contain any terminal in FOLLOW (A)
	
	Left recursive grammar can be converted to equivalent right recursive grammar. 
		A -> Aa | b 
						to 
		A -> bA`
		A` -> aA` | ε
	Steps :
			A → Aα | β
			to an equivalent grammar (right recursive)
			A → βA`
			A` → αA` | ϵ


## Bottom Up Parsing
	Equivalentlty does a rightmost derivation in reverse order.
### Shift reduce parsing 
	A kind of bottom up parsing. A stack holds grmmar symbols and a buffer holds the input string.
	Start wiht $ as the only symbol in the stack.
	The input strings are shifted into the stack until a reduction can be done. (aks a handle is found)
	head -> tail.
	when a tail is found in the stack it is reduced to its corresponding head.
	Four possible actions : shift/reduce/accept/error

#### Handle
	A handle in a right-sentential form γ is a production A -> b and a postion in γ where b may be found.
		- for convenience b is called the handle instead of A -> b
		- A right sentential form is a string that can be dervied by right deriving a Start symbol.
#### Handle Pruning
	The handles are pruned to get the previous sentitential form. This is repeated until the start symbol is found.
	- Locating a handle is hard, you may sometimes need to examine the whole stack to find one.

#### Parser States
	- State indicates how much of a production the parser has seen.
	- current state will be on top of the stack.
	- parse makes decision based on the state and the next input symbol.
#### Item
	- indicates how much of a production the parser has seen.
	- a parser is represeted by a set of items.
	- A -> a.b parser has seen until a and may go a reduction A -> a
	- A -> ab. parser has seen until b and may go a reduction A -> ab
##### LR(0) Items
	- an item of the form A -> a.b is called an LR(0) item.
	- a state of the parser is defined by a set of lr(0) items.
#### Augmented Grammar
	- a new production S` -> S
	- parser accepts when when it is about to reduce S` -> S
#### Closure of set of items
	- add every item in I to closure(I)
	- If A → α.Bβ is in Closure(I) then for each production B → γ, add B → .γ to Closure(I).
	- exmaple : 
		S′ → S
		S → L = R
		L → id
		R → num
		Closure({S → .L = R}) = {S → .L = R, L → .id}
		Closure({S → L = .R}) = {S → L = .R, R → .num}
### Goto
	Goto(I, X) where I is a set of items and X is a grammar symbol is defined to be the set of all items in the closure of A → αX.β such that A → α.Xβ is in I
	EXAMPLE : 
	S′ → S
	S → L = R
	L → id
	R → num
	Goto({S → L. = R}, =)
	is {S → L = .R, R → .num}


# Attribute Evaluation
## SDD (syntax directed definition)
	A notation for specifying syntax direction translation
	- context free grammar together with attributes and rules
	- 'attributes' associated with each grammar symbol
		- X.a denotes the value of a associated with X
		- attributes can be numbers, strings, boolean, types etc
	- rules associated with each production. Attribute values are computed as per the rules.
	- attribute values are obtained during lexical analysis

![[Pasted image 20250312201759.png]]
### Attribute evaluation
	- build a parse tree, visit the nodes of the tree and compute the attribute values
	- evaluate the attributes during parsing, without explicity building a parse tree.
### Order of evaluation -- Inherited and Synthesized Attributes --
	- If a syntax tree is build. Then the order of evalution should be a topological order.
	- for a synthesized attribute dependency edges goes from child to parent
		- meaning their type is found from the child. It flows upward
	- for an inherited attribute, dependency edges goes from parent to child or from sibling to sibling 
		- computed from parent nodes and flows downward

```C
/ addType(id.entry, T.type) -- What does this mean?
	- id.entry a pointer to an entry in the symbol table.
	- T.type represents the type of a variable
	- addType means to update the symbol table of id.entry to the type of T.type.
```
### Types of SDD
	1) S-attributed SDD :- involves only synthesized attributes
	2) L-attributed SDD :- attributes can be synthesized or inherited
		- added restriction that dependency graph edges between attributes of symbols in a producation body go from left to right
#### L-attributed SDD
	- Synthesize or
	- inherited
# Semantic Analysis
	- Semantic analysis is about the actual meaning. It's a step after parsing where we assign each token a specific category or value. For example an integer or a string. Does type checking, statics checking, and type conversions that can't be done by the syntax analyzer
	- Syntax analysis check if the program is syntatically valid and reports syntax errors.
	- type errors like following can't be found in syntax analysis stage
		- divide by zero
		- type mismatch
		- variable used without declaration
## Static checks
	Errors that can be check statically
		- type mismatch
		- variable used without declaration
		- check like array out of bounds require dynamic checking
## Symbol table
	- a data structure that stores information regarding the source program
	- one entry for each variable, constant, functions, labels with values of its attributes.
	- stores information collected during early stage of analysis, that will be required during later stages
	- possible attributes
		- variable name
			- type, scope, binding, name
		- function name
			- number of arguments, name, name and type of each argument, the method of passing each argument, return type.
### Symbol table management
	- Lexicaly analyzer
		- creates a symbol table entry for each identifier
		- token returned : <id entry, pointer to table entry

values are not stored in symbol table

| Name | Type  | ... |
| ---- | ----- | --- |
| x    | int   | ... |
| y    | float | ... |
![[Pasted image 20250313233735.png]]![[Pasted image 20250313234223.png]]

## Implementing Scope
	Scope of a declaration of a variable x is the portion of the program in which uses of x refer to this declaration.
	- static scope (C, java)
	- dynamic scope (determined at runtime)
### Block structured languages
	- a block is a grouping of declarations and statements
	- The scope of a variable x that is declared in block B is the entirety of block B except for nested blocks within B that redeclare x

## Type Checking
	Type: 
		- a set {} of values (domain of values)
		- a set of operations on these values
	Type checking: checks if the type of the operand matches the type expected by an operator.

![[Pasted image 20250314134012.png]]
## Type System
	A set of types and set of typing rules to assign types to various language constructs.
~ Question
	For the following C code fragment, indicate the type of the identifiers, a, b, c, f, and student:
```C 
	int a; float b; int c[10]; int f( int x, float y); struct student{int num; float marks;} 
	```
```Ruby
	a : data type : int
	b : data type : float
	c : data type : array of int
	f : return type : int 
		first parameter  : int x
		second parameter : float y
	student : data type : struct student 
```

	array(10, int)  :  an array of size 10 with base type int
	boolean f(int x)  :  int --> boolean is the type of f
	boolean f(int k, int q)  :  int x int --> boolean

### Type expression
	A type expression is used to denote the type of a language construct. 
	For example : 
	- a basic type like int, boolean, char, void, type_error(to signal error during type checking)
	- a type name
		- These are identifiers that represent specific types defined in the programming language.
	- a type constructor applied to appropriate arguments
		- Array types: int[] or Array<int>
		- Function types: (int, float) -> boolean
		- Struct or record types: struct { x: int, y: float }

### Type constructors
	- array(I, t) : the type constructor array applied to a number I and a type t
	- s -> t : the type constructor -> applied to type expression s and t, denotes the type of funcations with input s and return type t
	- s x t : type denoting list, tuple of types.
	- pointer(t) : dentoes the type of a pointer to an object with type t
	- record((l1 × t1) × (l2 × t2)): the type constructor record applied to a list of (label, type) pairs, denoting the type of a record

![[Pasted image 20250314145327.png]]
![[Pasted image 20250314145320.png]]
### Type conversions
	- implicit
		- adding and int and a float results in a float
	- explicit
		- casts in C

![[Pasted image 20250314145842.png]]

What is lvalue?
	short for left value. They represent the memory location and can appear on the left side of an assignment operator.
# Intermediate Representation
	The front end of the compiler produces an intermediate representation of the source program. 
		1) abstract syntax tree
			1) represents hierarchial syntatic structure of the source program.
			2) condensed form of parse tree. With variable names dropped or replaced by operators
			3) each construct is made of an operator node with sub trees corresponding to the semantically meaningful components of the construct
	
![[Pasted image 20250315132305.png]]		
			
			4) three address code
				1) instructions of the form a = b op c (1 address for the result and two for the operands)
				2) at most one operator on the right side of the instruction
				3) temporary names may be generated and used by the compiler to split a signle instructions to parts
					1) an address in a 3 address code can be
						1) a name in the source program
						2) a constant
						3) a compiler generated temporary
				4) instructions for altering flow of control.
				5) 
			5) DAG (directed acyclic graph) for expressions
			6) static single assignment form

![[Pasted image 20250315141701.png]]

	slist -> slist stmt | ϵ
		here slist is a right recursive structure.
		stmt is a placeholder for ifelse, while etc. 
		epsilon is the base case, acting as termination condition for recursion.

```text
if (...) { ... }  
while (...) { ... }

seq
├── seq
│   ├── seq
│   │   ├── null (ϵ)
│   │   └── if-statement
│   └── while-statement
| //rest of the code
```


## 3 address code generation
```text
x = a + b ∗ c 
	is converted to
t1 = b * c
t2 = a + t1
x = t2
where t1 and t2 are computer genrated temporaries
```
	Common instructions
	 - x = y op x
	 - x = op y where op is an unary operator
	 - copy instructions of the form x = y
	 - goto L; an unconditional jump
	 - if x goto L
	 - if x relop y goto L
	 - if False x goto L; if x is False goto L
```ruby
if (a < b) small = a else small = b . . .

converted into -> 
	if a < b goto L1
	goto L2
L1: small=a
	goto L3
L2: small=b
L3: . . .
```

### Procedure calls
	- a procedure call is a type of call that transfers control from current program to a specfic procedure allowing the execution of a defined set of instructions. 
	- procedure calls are broken as follow
		- p(arg1, arg2, arg3, ... , argn);
		- param arg1
		- param arg2
		- param arg3
		- ...
		- call p, n
	- call p, n triggers the procedure p where n is the number of arguments
		- return y
		- is called to return the control back to the orgianal program and assigns value y to the caller.
#### Array addressing
    `x[i] = y` (store `y` into index `i` of `x`):
```text
    t = x + i  ; Calculate address offset   *t = y     ; Store value
```
  - Three address code has 4 parts. 
	  - op - code for operator
	  - arg1
	  - arg2
	  - result

## DAG for Expressions
	- graph nodes corresponding to operands and operators
	- common operand nodes (representing subexpressions) are not replicated
	- can identify common subexpressions

 - Take (a + b) * (a + b)
						![[Pasted image 20250315153855.png]]
Here a + b is represented only once and used twice. Reducing redundancy.

 - a + a * b
						![[Pasted image 20250315153930.png]]


## Static Single Assignment (SSA) Form
	- all assignments are to variables with distinct names
	- SSA facilitates code optimizations
	- definition of same variables are changed to different variables.
		- x = a + b
		- x = p + q
			- is changed to 
		- x1 = a + b
		- x2 = p + q
	- Use of ϕ functions
		- this function automatically finds the control flow and assigns the appropriate variable

```python
if (. . .) x = 1 else x = 2;
y = x;
	represented in SSA as:
if (. . .) x1 = 1 else x2 = 2;
x3 = ϕ(x1, x2);
y = x3;
```

# 3 Address code generation
![[Pasted image 20250316102802.png]]

	- E.addr represents the memory addr that will hold E (it can be a name, a constant or a computer generated temporary)
	- E.code represents the 3 addr code for E
	- id.entry points to the symbol table entry for id
	- newTemp() returns a distinct new temporary name
	- gen() returns a generated 3 addr code. The qouted values stay the same and others are converted to its values

																		
![[Pasted image 20250316103833.png]]
==Concatenating E1.code and E2.code to the front of E.code ensures that E1.code and E2.code are executed before E.code is executed.==
==E1 and E2 are evaluated and stored in temporary variables like E1.addr and E2.addr. This also avoids register conflicts when there are multiple expressions==

## Booleans and Conditional operators

```
if (a < b) small = a else small = b

IS CONVERTED TO ....
	if a < b goto L1
		goto L2
	L1: small=a
		goto L3
	L2: small=b
	L3:
```
![[Pasted image 20250316111229.png]]
	B.True and B.False are labels
	So it should have B.True = newLabel() and B.False = newLable()
![[Pasted image 20250316111628.png]]

==`S.next` defines the **exit label** for a statement block (e.g., where to jump after the block completes)==


	newLabel() returns a new unique temporary name
	S.next : address or label of the instructions that should follow immediately
	label(L) : attaches a label to the next 3 address code that should be generated.
			here label(B.true) is attached to S1.code
			Also S.code contains the jump instruction to go to either B.true or B.false

![[Pasted image 20250316114114.png]]

### Short circuit evaluation semantics
	- in B1 || B2 if B1 evalutes to true then there is no need to evaluate B2
	- Complete evalutation semantics evaluates both
	- in short circuit code the boolean operators (< || &&) are converted to jump operations. The operators don't appear in the code.

```C
if (x < y && x < z ) then S1 else S2:


	if x < y goto L1
	goto L3
	L1: if x < z goto L2
	goto L3
	L2 : S1
	goto L4
	L3 : S2
	L4 :

```

![[Pasted image 20250316133500.png]]

### While loop 3 address code
```
while (i < 10) i = i + 1:

	L1: if i < 10 goto L2
	goto L3
	L2: t1 = i + 1
	i = t1
	goto L1
	L3 :
```

![[Pasted image 20250316150956.png]]

### What are programs?

	Program: A structured sequence of code blocks with control flow (e.g., loops, conditionals) and labels, forming a complete executable unit.
	Example:
```text
L1: if x < y goto L2  
	goto L3  
L2: small = x  
	goto L4  
L3: small = y  
L4:  
```
	
	The attributes B.true, B.false and S.next are inherited.
	Generated code will contain jump instructions with target
	labels unspecified.
	A second pass will be required for binding labels to addresses

## Backpatching
	- a techinque that is used to generate code and assign label address in a single pass.
	- A list is kept of B.truelist, B.falselist and S.nextList.
	- when the actual value if found the list is used to update the target labels in the instructions.
	- S is statement aka a sequence of statements or a block of code
	- B is boolean