
# Lexical Analysis
	Reads stream of characters and groups them into meaningful units called lexems or lexical units. Corresponding to each lexeme it returns a token to the parser.
		A Token is an entity composed of a name and an optional attribute.
		It also strips out whitespaces, comments and correlates  errors with the corresponding line numbers in the source program. 
		Lexical units can be classified into identifiers, keywords, punctuations, operators, numeric constants, literals etc.
		LEX analyser  returs a token corresponding to each category. For example id for identifier. The token contains additional attribute pertaining to the it. Commonly it contains a pointer to the symbol table entry for the identifier.
		Numeric constant :- *id* with attribute as the constant value
		Literal :- *literal* with string constant as the attribute value
		Operator :- *op* with operator as attribute or a single token for the symbol like *plus* or *minus*

```C
	== 3.14 ∗ 16 ∗ 16
    == < num, 3.14 > < op, ∗ > < num, 16 > < op, ∗ > < num, 16 >
```
## Pattern specification
	For each token there should be a regular expression that matches it. The lexer should know the pattern describing each token.
	A string that matches the pattern for a token is know as a lexeme.

```ruby
digit → 0|1|2|3|4|5|6|7|8|9
letter → A|B| . . . |Z|a|b| . . . |z
id → letter(letter|digit)
```

	 Here the arrow assigns a name to each regular expression. Then these names can be used instead of the regualr expression.


## Recognition of tokens
	Reads input stream and returns token corresponding to longest matching prefix. The recognition process can be modeled with a state transition diagram.

![[Pasted image 20250122203850.png]]

	Sometimes the scanner needs to scan an additional symbol that is not part of the lexeme. In that case the pointer needs to be brought back by one position this is denoted by a -- * -- symbol.

### Automatic lexical analyzer generator
	Tools like lex/flex can be used to generate lexical analysers.
	The specifications of the required analyzer is written as a Lex Program in a Lex file. The file is written as a combination of regualr expressions, describing the pattern for the tokens. The lex compiler compiles the program into a C program, which contains an equivalent finite automaton and providing a driver for the automaton. Given n patterns P1 P2 P3 the tool builds a combined regular expression P1|P2|P3. In the lex program a code fragment can be associated with each pattern. The code is run when the longest prefix of the input matches the correspoding pattern.


# Parsing
## Types
	1) Universal 
		parse any grammar (CYK algorithm) n^3 algo
		1) Compilers commonly use
			1) Top Down parsing
			2) Bottom Up parsing
## Lexical Analysis
	Input : Program as a stream of characters, And the specification of tokens.
	Output : Stream of tokens (one token corresponding to each lexeme)
## Syntax Analysis aka parsing
	Input : Token stream, Syntax specification of the programming language in the form of context free grammar(CFG)
	Checks if sequence of token names can be generated by the given grammar by simulating the parse tree.
	Create/Update symbol table entries, type checking, intermediate code generation.
	Output : Parse tree, or some intermediate representation of the program, if parsing is successful.

### BNF ( Backus-Naur Form)
	
### CFG (Context Free Grammar)
	G = (V, T, P, S)
		Variables/Non Terminals, Terminals, Productions rules, Start symbol
#### Derivation
	i/p : id = id + id
	
![[Pasted image 20250124150316.png]]

	derivation : replace a non terminal with a string of grammar symbols.

![[Pasted image 20250124150425.png]]

#### Sentential form
$$
	 If \space S \star\rightarrow \alpha \space we \space say \space \alpha \space is \space in \space sentential \space form  
$$
	
	A Sentence is a sentential form with non non-terminals.

$$
L(G) \space is \space the \space set \space of \space sentences \space derivalbe \space from \space the \space start \space symbol \space G
$$
$$
A \space string \space of \space symbols \space \epsilon \space L(G) \space only \space if \space S \space \star \rightarrow w 
$$
	Leftmost derivation : keep deriving the leftmost non-terminal
	Rightmost derivation : keep deriving the rightmost non-terminal
### Parsing
#### Parse trees
![[Pasted image 20250124151435.png]]

	An ambigous grammar has more than one leftmost derivation or rightmost derivation or parse tree.
#### Top down parsing
	Start from root node as the start symbol. Keep adding nodes in preorder.
	PREORDER
		visit current node
		visit left node in preorder
		visit right node in preorder
	HOW ?
		if non terminal
			choose appropriate production and add nodes
		if terminal
			skip to next node
	This is equivalent to finding a leftmost derivation

#### Bottom-Up Parsing
	Start with leaf nodes represnting the input stream of characters.
	At each step replace the leftmost symbol with a matching production symbol.

#### Recursive decent parsing
```C
S(){
	match(‘c’);
	A();
	match(‘d’);
}
A(){
	match(‘a’);
	match(‘b’);
}
// match(x) : compares the next input symbol, if same : advances the pointer by one, else : reports error.
```

		Recursive-Descent with backtracking, if multiple choices, choose one, if error occurs go back and choose next, if eroor persists for all choices return error.

#### Predictive parsing
	keep a lookahead pointer that points to the next symbol, then try to match the lookahead symbol with a production rule. parser predicts the production based on the look-ahead symbol.
##### FIRST(A)
	Defined as the set of first non-terminals that can be derived from the symbol A. empty symbol can also be in FIRST(A) 
	eg: A -> B | C
		B -> amk
		B -> ksg
		C -> qwe

$$FIRST (A) = FIRST(B)  \cup  FIRST(C) =  {a, k, q}$$
$$FIRST(B) = {a, k}$$
$$FIRST(C) = {q}$$
	If lookahead an element in FIRST(B) choose B else if element in FIRST(C) choose C else error.
	If FIRST(B) and FIRST(C) are disjoint a parsing decision can be made by the lookahead symbol. 
	If A -> a then add everything in FIRST(a) to FIRST(A)

#### Predictive parsing table based on FIRST sets

|     | id            | num                | -                | $         |
| --- | ------------- | ------------------ | ---------------- | --------- |
| $S$ | $S → id = E$  | **error**          | **error**        | **error** |
| $E$ | $E → id + id$ | $E\rightarrow num$ | $E\rightarrow -$ | **error** |

	Algorithm : 
		for each production A -> a:
			for each symbol k in FIRST(a):
				add A -> a in entry T[A, k]

#### CFG with null production
	A -> Cd
	C -> ab | ε
	Where will we choose C -> ε production ? 

![[Pasted image 20250124162037.png]]

	if d ε FOLLOW(C)
#### FOLLOW(A)
	The set of terminals that can appear to the right of A in a sentential form. In addition if it is the rightmost symbol in some sentential form then $ is also in the set of FOLLOW(A). -- SENTENTIAL FORM --
	Try writing the sentential forms and write follow from that, even an intermediate step is enough to be included as a FOLLOW element.
	If A -> aB add everything in FOLLOW(A) to FOLLOW(B)
	
																											S ∗⇒ αAaβ
	1) S $
	2) E + E $
	3) id + E $
	Here S is followed by $, E is followed by + and $, id is followed by + and likewise.
	Steps to compute FOLLOW(S): S is the start symbol
		1) place $ in FOLLOW(S)
		2) if there is a production A -> aBb then add everthing except ε of FIRST(b) in FOLLOW(B)
		3) if there is a produtction A -> aBb and if b contains ε then add everything in FOLLOW(A) to FOLLOW(B)
		4) if there is a production A -> aB then add everything in FOLLOW(A) to FOLLOW(B)
#### Parsing table using follow
![[Pasted image 20250124175243.png]]

![[Pasted image 20250124175248.png]]

	for each production A -> a:
		if € an element of FIRST(a):
			for each terminal b € FOLLOW(A):
				add (A -> a) in T[A, b]
	Productions like this are not suitable for predictive parsing:
	
																						E → id + id | id ∗ id 
	Steps in making creating predictive parsing table:
		1) for each terminal a ε FIRST(A) add A -> a in T[A, a]
		2) if ε in FIRST(A), for each terminal b in FOLLOW(A) add A -> a in T[A, b]
			because sometimes you might need to choose a production that gives epsilon on first to get the correct symbol which might come in the second position.
		3) if ϵ is in FIRST(α), and $ is in FOLLOW (A), add A → α to T[A, $].

#### Grammar Transformation
	Convert the given non predictive grammar to an equivalent predictable form.
	E → id + id | id ∗ id
	an equivalent grammar suitable for predictive parsing
	E → idB
	B → +id | ∗ id

##### Left Factoring
	E → id + id | id ∗ id
	id is common on the left side, that is maintained and rest is replaced by B
	E → idB
	B →  + id | ∗ id
##### Right Factoring

	

### Non Recursive Predictive Parsing

	Input : string S and Parsing table T for grammar G
	Output : If S belong to grammar G or not. IF yes give leftmost derivation of w.

### LL(1) Grammar
	A grammar for which predictive parsing table can be built with one symbol look ahead is called LL(1) grammar. 
	- Left to right
	- Leftmost derivation 
	- 1 for one symbol look ahead.
	- E → id + id | id ∗ id is not LL(1) because it needs to look ahead two symbols to decide the next production.
	- if A -> a | b and FIRST(a) intersection FIRST(b) is not null then it is not suitable for predictive parsing.
#### Rules
	1) FIRST(a), FIRST(b) should be disjoint
	2) If ε is in FIRST(A), then FIRST(B) should not contain any terminal in FOLLOW(A)
	3) If ϵ is in FIRST(β), then FIRST(α) should not contain any terminal in FOLLOW (A)
	
	Left recursive grammar can be converted to equivalent right recursive grammar. 
		A -> Aa | b 
						to 
		A -> bA`
		A` -> aA` | ε
	Steps :
			A → Aα | β
			to an equivalent grammar (right recursive)
			A → βA`
			A` → αA` | ϵ


## Bottom Up Parsing
	Equivalentlty does a rightmost derivation in reverse order.
### Shift reduce parsing 
	A kind of bottom up parsing. A stack holds grmmar symbols and a buffer holds the input string.
	Start wiht $ as the only symbol in the stack.
	The input strings are shifted into the stack until a reduction can be done. (aks a handle is found)
	head -> tail.
	when a tail is found in the stack it is reduced to its corresponding head.
	Four possible actions : shift/reduce/accept/error

#### Handle
	A handle in a right-sentential form γ is a production A -> b and a postion in γ where b may be found.
		- for convenience b is called the handle instead of A -> b
		- A right sentential form is a string that can be dervied by right deriving a Start symbol.
#### Handle Pruning
	The handles are pruned to get the previous sentitential form. This is repeated until the start symbol is found.
	- Locating a handle is hard, you may sometimes need to examine the whole stack to find one.

#### Parser States
	- State indicates how much of a production the parser has seen.
	- current state will be on top of the stack.
	- parse makes decision based on the state and the next input symbol.
#### Item
	- indicates how much of a production the parser has seen.
	- a parser is represeted by a set of items.
	- A -> a.b parser has seen until a and may go a reduction A -> a
	- A -> ab. parser has seen until b and may go a reduction A -> ab
##### LR(0) Items
	- an item of the form A -> a.b is called an LR(0) item.
	- a state of the parser is defined by a set of lr(0) items.
#### Augmented Grammar
	- a new production S` -> S
	- parser accepts when when it is about to reduce S` -> S
#### Closure of set of items
	- add every item in I to closure(I)
	- If A → α.Bβ is in Closure(I) then for each production B → γ, add B → .γ to Closure(I).
	- exmaple : 
		S′ → S
		S → L = R
		L → id
		R → num
		Closure({S → .L = R}) = {S → .L = R, L → .id}
		Closure({S → L = .R}) = {S → L = .R, R → .num}
### Goto
	Goto(I, X) where I is a set of items and X is a grammar symbol is defined to be the set of all items in the closure of A → αX.β such that A → α.Xβ is in I
	EXAMPLE : 
	S′ → S
	S → L = R
	L → id
	R → num
	Goto({S → L. = R}, =)
	is {S → L = .R, R → .num}

# Semantic Analysis
	Semantic analysis is about the actual meaning. It's a step after parsing where we assign each token a specific category or value. For example an integer or a string.

